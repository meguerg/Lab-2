# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wY8R5IA0vka0votPrWpzLJH0vtrKY5Qp

**K-Nearest Neighbors Algorithm**
"""

from google.colab import drive

drive.mount('/content/drive')

!pip install pyspark

!pip install scikit-learn

from pyspark.sql import SparkSession

from pyspark.sql.functions import *

from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql import functions as F
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
import pandas as pd
import numpy as np

spark = SparkSession.builder.appName("KNNExample").getOrCreate()

df = spark.read.csv("/content/train.csv", header=True, inferSchema=True)

selected_columns = ["Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"]
df = df.select(selected_columns)

df.show()

df = df.na.drop()

df.show()

df = df.withColumn("Sex", F.when(df["Sex"] == "male", 0).otherwise(1))

df.show()

assembler = VectorAssembler(
    inputCols=["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"],
    outputCol="features"
)
df = assembler.transform(df)

df=df.withColumn('Age',df['Age'].cast('Integer'))
df=df.withColumn('Fare',df['Fare'].cast('Integer'))

df.show()

mean_values = df.agg(*[F.mean(c).alias(c) for c in df.columns if c != "features"]).collect()[0]
stddev_values = df.agg(*[F.stddev(c).alias(c) for c in df.columns if c != "features"]).collect()[0]

df.show()

for col in df.columns:
    if col != "features":
        df = df.withColumn(col, (df[col] - mean_values[col]) / stddev_values[col])

pandas_df = df.select("features", "Survived").toPandas()

X = np.array([np.array(row) for row in pandas_df["features"]])
y = np.array(pandas_df["Survived"])

knn_classifier = KNeighborsClassifier(n_neighbors=5)

df = df.withColumn("Survived", df["Survived"].cast("integer"))

pandas_df = df.select("features", "Survived").toPandas()

X = np.array([np.array(row) for row in pandas_df["features"]])
y = np.array(pandas_df["Survived"])

knn_classifier = KNeighborsClassifier(n_neighbors=5)

cv_scores = cross_val_score(knn_classifier, X, y, cv=5, scoring="accuracy")

print("Cross-validation scores:", cv_scores)
print("Mean accuracy:", np.mean(cv_scores))

train, test = df.randomSplit([0.8, 0.2], seed=42)

from pyspark.sql.types import DoubleType


predictions_df = spark.createDataFrame(
    zip(predictions.tolist(), test.select("Survived").toPandas()["Survived"].tolist()),
    ["prediction", "Survived"]
)


predictions_df = predictions_df.withColumn("prediction", predictions_df["prediction"].cast(DoubleType()))


evaluator = MulticlassClassificationEvaluator(labelCol="Survived")
accuracy = evaluator.evaluate(predictions_df, {evaluator.metricName: "accuracy"})


print("Accuracy on the test set:", accuracy)

